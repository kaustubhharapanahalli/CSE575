{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "N68seRK9-TJx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BEfzQeih-cdB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          session_id  index  elapsed_time      event_name   name level  page  \\\n",
      "0  20090312431273200      0             0  cutscene_click  basic     0   NaN   \n",
      "1  20090312431273200      1          1323    person_click  basic     0   NaN   \n",
      "2  20090312431273200      2           831    person_click  basic     0   NaN   \n",
      "3  20090312431273200      3          1147    person_click  basic     0   NaN   \n",
      "4  20090312431273200      4          1863    person_click  basic     0   NaN   \n",
      "\n",
      "   room_coor_x  room_coor_y  screen_coor_x  screen_coor_y  hover_duration  \\\n",
      "0  -413.991394  -159.314682          380.0          494.0             NaN   \n",
      "1  -413.991394  -159.314682          380.0          494.0             NaN   \n",
      "2  -413.991394  -159.314682          380.0          494.0             NaN   \n",
      "3  -413.991394  -159.314682          380.0          494.0             NaN   \n",
      "4  -412.991394  -159.314682          381.0          494.0             NaN   \n",
      "\n",
      "                            text    fqid                       room_fqid  \\\n",
      "0                      undefined   intro  tunic.historicalsociety.closet   \n",
      "1  Whatcha doing over there, Jo?  gramps  tunic.historicalsociety.closet   \n",
      "2         Just talking to Teddy.  gramps  tunic.historicalsociety.closet   \n",
      "3     I gotta run to my meeting!  gramps  tunic.historicalsociety.closet   \n",
      "4            Can I come, Gramps?  gramps  tunic.historicalsociety.closet   \n",
      "\n",
      "                                           text_fqid fullscreen   hq music  \\\n",
      "0               tunic.historicalsociety.closet.intro        NaN  NaN   NaN   \n",
      "1  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
      "2  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
      "3  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
      "4  tunic.historicalsociety.closet.gramps.intro_0_...        NaN  NaN   NaN   \n",
      "\n",
      "  level_group  \n",
      "0         0-4  \n",
      "1         0-4  \n",
      "2         0-4  \n",
      "3         0-4  \n",
      "4         0-4  \n",
      "(13174211, 20)\n"
     ]
    }
   ],
   "source": [
    "dtypes = {\n",
    "    'elapsed_time': np.int32,\n",
    "    'event_name': 'category', \n",
    "    'name': 'category',\n",
    "    'level': 'category',\n",
    "    'room_coor_x': np.float32,\n",
    "    'room_coor_y': np.float32,\n",
    "    'screen_coor_x': np.float32,\n",
    "    'screen_coor_y': np.float32,\n",
    "    'hover_duration': np.float32,\n",
    "    'text': 'category',\n",
    "    'fqid': 'category',\n",
    "    'room_fqid': 'category',\n",
    "    'text_fqid': 'category',\n",
    "    'fullscreen': 'category',\n",
    "    'hq': 'category',\n",
    "    'music': 'category',\n",
    "    'level_group': 'category'\n",
    "}\n",
    "df = pd.read_csv('data/train.csv', dtype=dtypes)\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "y-TcqH6l_ERz"
   },
   "outputs": [],
   "source": [
    "df.set_index(['session_id', 'index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "o3h_zf-S_E2z"
   },
   "outputs": [],
   "source": [
    "df = df[['event_name', 'name', 'level', 'room_coor_x', 'room_coor_y', 'screen_coor_x', 'screen_coor_y', 'hover_duration']]\n",
    "for col in ['room_coor_x', 'room_coor_y', 'screen_coor_x', 'screen_coor_y', 'hover_duration']:\n",
    "    df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
    "    df[col] = df[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2A6j-fw9_PNt"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "\n",
    "class OneHotEncoding(sklearn.base.TransformerMixin):\n",
    "    def __init__(self, dtypes=None):\n",
    "        self.input_columns = None\n",
    "        self.final_columns = None\n",
    "        if dtypes is None:\n",
    "            dtypes = [object, 'category']\n",
    "        self.dtypes = dtypes\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.input_columns = list(X.select_dtypes(self.dtypes).columns)\n",
    "        X = pd.get_dummies(X, columns=self.input_columns)\n",
    "        self.final_columns = X.columns\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None, **kwargs):\n",
    "        X = pd.get_dummies(X, columns=self.input_columns)\n",
    "        X_columns = X.columns\n",
    "        # if columns in X had values not in the data set used during\n",
    "        # fit add them and set to 0\n",
    "        missing = set(self.final_columns) - set(X_columns)\n",
    "        for c in missing:\n",
    "            X[c] = 0\n",
    "        # remove any new columns that may have resulted from values in\n",
    "        # X that were not in the data set when fit\n",
    "        return X[self.final_columns]\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return tuple(self.final_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eRamJHL5_g8n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13174211, 45)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneHotEncoding = OneHotEncoding()\n",
    "df = oneHotEncoding.fit_transform(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iXJoL8v6_qTX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id\n",
       "20090312431273200    [[0.4850341, 0.519125, 0.19832985, 0.34329396,...\n",
       "20090312433251036    [[0.49087286, 0.6860453, 0.20824635, 0.1737317...\n",
       "20090314121766812    [[0.482883, 0.6737315, 0.19467641, 0.18624045,...\n",
       "20090314363702160    [[0.589824, 0.64226294, 0.3763048, 0.21820709,...\n",
       "20090314441803444    [[0.49609697, 0.5519618, 0.217119, 0.30993745,...\n",
       "                                           ...                        \n",
       "22100215342220508    [[0.5649326, 0.4650811, 0.33402923, 0.39819318...\n",
       "22100215460321130    [[0.48160797, 0.7014448, 0.20563674, 0.1688672...\n",
       "22100217104993650    [[0.4819611, 0.65799725, 0.19311064, 0.2022237...\n",
       "22100219442786200    [[0.48564872, 0.50339067, 0.19937369, 0.359277...\n",
       "22100221145014656    [[0.42572483, 0.6573131, 0.09759916, 0.2029187...\n",
       "Length: 11779, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data = df.groupby('session_id').apply(lambda x: np.array(x))\n",
    "grouped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ghWLu1A9_r6g"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get the numpy array at the given index\n",
    "        return torch.from_numpy(self.data[idx]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "JmAzV0XV_26S"
   },
   "outputs": [],
   "source": [
    "def collate_fn_padd(batch):\n",
    "    \"\"\"\n",
    "    Padds batch of variable length\n",
    "\n",
    "    Note: it converts things ToTensor manually here since the ToTensor transform\n",
    "    assume it takes in images rather than arbitrary tensors.\n",
    "    \"\"\"\n",
    "    ## Get sequence lengths\n",
    "    lengths = [t.shape[0] for t in batch]\n",
    "    try:\n",
    "        n_features = batch[0].shape[1]\n",
    "    except:\n",
    "        n_features = 1\n",
    "    max_length = max(lengths)\n",
    "    if max_length == 0:\n",
    "        max_length += 1\n",
    "    batch_size = len(lengths)\n",
    "\n",
    "    padded_tensor = torch.zeros(batch_size, max_length, n_features, dtype=torch.float32)\n",
    "    for i, val in enumerate(batch):\n",
    "        l = lengths[i]\n",
    "        if n_features == 1:\n",
    "            padded_tensor[i, :l] = val.reshape(-1, 1)\n",
    "        else:\n",
    "            padded_tensor[i, :l] = val\n",
    "    \n",
    "    return padded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mLjr2AqO_82N"
   },
   "outputs": [],
   "source": [
    "dataset = MyDataset(grouped_data.values)\n",
    "\n",
    "# Create a PyTorch DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn_padd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "qTdZLx6EABkO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_1</th>\n",
       "      <th>q_2</th>\n",
       "      <th>q_3</th>\n",
       "      <th>q_4</th>\n",
       "      <th>q_5</th>\n",
       "      <th>q_6</th>\n",
       "      <th>q_7</th>\n",
       "      <th>q_8</th>\n",
       "      <th>q_9</th>\n",
       "      <th>q_10</th>\n",
       "      <th>q_11</th>\n",
       "      <th>q_12</th>\n",
       "      <th>q_13</th>\n",
       "      <th>q_14</th>\n",
       "      <th>q_15</th>\n",
       "      <th>q_16</th>\n",
       "      <th>q_17</th>\n",
       "      <th>q_18</th>\n",
       "      <th>total_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20090312431273200</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20090312433251036</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20090314121766812</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20090314363702160</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20090314441803444</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22100215342220508</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22100215460321130</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22100217104993650</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22100219442786200</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22100221145014656</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11779 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   q_1  q_2  q_3  q_4  q_5  q_6  q_7  q_8  q_9  q_10  q_11  \\\n",
       "session                                                                      \n",
       "20090312431273200    1    1    1    1    1    1    1    1    1     1     1   \n",
       "20090312433251036    0    1    1    1    0    1    1    0    1     0     0   \n",
       "20090314121766812    1    1    1    0    0    1    1    0    0     1     1   \n",
       "20090314363702160    1    1    1    1    1    1    1    1    1     1     1   \n",
       "20090314441803444    1    1    1    1    1    1    0    1    0     1     0   \n",
       "...                ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "22100215342220508    1    1    1    1    1    1    1    0    1     1     1   \n",
       "22100215460321130    0    1    1    1    0    1    1    0    1     0     1   \n",
       "22100217104993650    1    1    1    1    1    1    1    1    1     0     1   \n",
       "22100219442786200    0    1    1    1    1    1    1    0    1     0     1   \n",
       "22100221145014656    0    1    0    1    0    0    0    0    1     0     1   \n",
       "\n",
       "                   q_12  q_13  q_14  q_15  q_16  q_17  q_18  total_score  \n",
       "session                                                                   \n",
       "20090312431273200     1     0     1     1     0     1     1           16  \n",
       "20090312433251036     1     0     1     0     1     0     1           10  \n",
       "20090314121766812     1     0     1     1     1     0     1           12  \n",
       "20090314363702160     1     0     1     0     0     1     1           15  \n",
       "20090314441803444     1     0     1     1     1     1     1           14  \n",
       "...                 ...   ...   ...   ...   ...   ...   ...          ...  \n",
       "22100215342220508     1     0     1     1     1     1     1           16  \n",
       "22100215460321130     1     0     1     0     1     1     1           12  \n",
       "22100217104993650     1     1     1     0     0     1     1           15  \n",
       "22100219442786200     1     0     1     0     1     1     1           13  \n",
       "22100221145014656     1     0     0     0     0     1     1            7  \n",
       "\n",
       "[11779 rows x 19 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = pd.read_csv('data/train_labels.csv')\n",
    "label_df['session'] = label_df.session_id.apply(lambda x: int(x.split('_')[0]) )\n",
    "label_df['question_idx'] = label_df.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )\n",
    "label_df.drop(\"session_id\", axis=1, inplace=True)\n",
    "pivoted_questions = label_df.pivot(columns='question_idx', values='correct', index='session')\n",
    "pivoted_questions['total_score'] = pivoted_questions.iloc[:, 0:18].sum(axis=1)\n",
    "pivoted_questions.columns = [f'q_{i}' for i in range(1, 19)] + ['total_score']\n",
    "pivoted_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "RQG4Fw5NAJrH"
   },
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "class StackedLSTM(nn.Module):\n",
    "    def __init__(self, n_layers, n_hidden, n_features, n_embeddings):\n",
    "        super(StackedLSTM, self).__init__()\n",
    "        self.embedding = nn.Linear(n_features, n_embeddings)\n",
    "        self.lstm = nn.LSTM(n_embeddings, n_hidden, n_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(n_hidden, 18)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input through the Embedding layer\n",
    "        embed_out = self.embedding(x)\n",
    "\n",
    "        # Pass the input through the LSTM layers\n",
    "        lstm_out, _ = self.lstm(embed_out)\n",
    "\n",
    "        # Get only the last output of the LSTM layer\n",
    "        out = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Flatten the LSTM output and pass it through the linear layer\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        # Apply sigmoid activation function to the output\n",
    "        out = torch.sigmoid(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Create an instance of the model\n",
    "n_layers = 5  # Number of LSTM layers\n",
    "n_hidden = 32  # Number of LSTM units\n",
    "n_embeddings = 16 # Number of dimension in embedding layer\n",
    "n_features = 45  # Number of features in each sequence\n",
    "\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "model = StackedLSTM(n_layers, n_hidden, n_features, n_embeddings).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vCGqE84DAMAZ",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:36,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.5515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:34,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:35,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Loss: 0.5525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:34,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Loss: 0.5525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:34,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Loss: 0.5525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:33,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Loss: 0.5529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:30,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Loss: 0.5522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:31,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:31,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:30,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:30,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Loss: 0.5522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:30,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:31,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:30,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:31,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:33,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:32,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:33,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:34,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, Loss: 0.5522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:33,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Loss: 0.5522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:32,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Loss: 0.5522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:31,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, Loss: 0.5522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:35,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, Loss: 0.5522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:32,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Loss: 0.5522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:33,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, Loss: 0.5522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:32,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:32,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:32,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:34,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:31,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:31,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:33,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:33,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:35,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:33,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:33,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:31,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:32,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:33,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:33,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:32,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:32,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:34,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:33,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:33,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:33,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:33,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:33,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:33,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [02:30,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50, Loss: 0.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Define number of output labels (number of questions)\n",
    "n_out = 18\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Define the number of epochs\n",
    "n_epochs = 50\n",
    "\n",
    "# Data size\n",
    "n_samples = len(grouped_data)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    for i, sample in tqdm(enumerate(dataloader)):\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Get label\n",
    "        labels = torch.from_numpy(pivoted_questions.iloc[i*batch_size:(i+1)*batch_size, :18].values).float()\n",
    "        \n",
    "        sample = sample.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(sample)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sample = sample.to('cpu')\n",
    "        labels = labels.to('cpu')\n",
    "        \n",
    "    # Print the loss after every epoch\n",
    "    print(f'Epoch {epoch+1}/{n_epochs}, Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "j6DQa1ZPAOPH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [00:53,  6.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "pred_list = []\n",
    "true_list = []\n",
    "\n",
    "model.eval()\n",
    "for i, sample in tqdm(enumerate(dataloader)):\n",
    "    model.zero_grad()\n",
    "        \n",
    "    # Get label\n",
    "    labels = torch.from_numpy(pivoted_questions.iloc[i*batch_size:(i+1)*batch_size, :18].values).float()\n",
    "    \n",
    "    sample = sample.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(sample)\n",
    "\n",
    "    sample = sample.to('cpu')\n",
    "    labels = labels.to('cpu')\n",
    "\n",
    "    pred_list.append(outputs.data.cpu().numpy())\n",
    "    true_list.append(labels.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Pjd8qP8jAPn7"
   },
   "outputs": [],
   "source": [
    "test_pred_flattened = np.concatenate(pred_list).ravel()\n",
    "test_true_flattened = np.concatenate(true_list).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "tssAncpuAWKV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7313392006489893\n",
      "0.7448478223957891\n",
      "0.9405368102269986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(accuracy_score(test_true_flattened, np.round(test_pred_flattened)))\n",
    "print(precision_score(test_true_flattened, np.round(test_pred_flattened)))\n",
    "print(recall_score(test_true_flattened, np.round(test_pred_flattened)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "zHRGUvwrAWtm"
   },
   "outputs": [],
   "source": [
    "# For test set\n",
    "\n",
    "# Remove the training set to save RAM\n",
    "del(df)\n",
    "del(grouped_data)\n",
    "del(dataloader)\n",
    "del(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0VCaPE-AZVS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  8.57it/s]"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('data/test.csv', dtype=dtypes)\n",
    "test_df.set_index(['session_id', 'index'], inplace=True)\n",
    "\n",
    "test_df = test_df[['event_name', 'name', 'level', 'room_coor_x', 'room_coor_y', 'screen_coor_x', 'screen_coor_y', 'hover_duration']]\n",
    "for col in ['room_coor_x', 'room_coor_y', 'screen_coor_x', 'screen_coor_y', 'hover_duration']:\n",
    "    # Scaling the coordinates and durations\n",
    "    test_df[col] = (test_df[col] - test_df[col].min()) / (test_df[col].max() - test_df[col].min())\n",
    "    test_df[col] = test_df[col].fillna(0)\n",
    "    \n",
    "test_df = oneHotEncoding.transform(test_df)\n",
    "grouped_data = test_df.groupby('session_id').apply(lambda x: np.array(x))\n",
    "\n",
    "dataset = MyDataset(grouped_data.values)\n",
    "dataloader = DataLoader(dataset, batch_size=3, shuffle=True, collate_fn=collate_fn_padd)\n",
    "\n",
    "# Make predictions\n",
    "pred_list = []\n",
    "\n",
    "model.eval()\n",
    "for i, sample in tqdm(enumerate(dataloader)):\n",
    "    model.zero_grad()\n",
    "    sample = sample.to(device)\n",
    "    # Forward pass\n",
    "    outputs = model(sample)\n",
    "    sample = sample.to('cpu')\n",
    "    pred_list.append(outputs.data.cpu().numpy())\n",
    "    \n",
    "pred_flattened = np.concatenate(pred_list).ravel()\n",
    "session_ids = test_df.index.get_level_values('session_id').unique().tolist()\n",
    "\n",
    "from functools import reduce\n",
    "session_ids = reduce(lambda x, y: x + [f'{y}_q{i}' for i in range(1, 19)], session_ids, [])\n",
    "\n",
    "test_result = pd.DataFrame({\n",
    "    'session_id': session_ids,\n",
    "    'correct': (pred_flattened > 0.6).astype('int')\n",
    "})\n",
    "test_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
